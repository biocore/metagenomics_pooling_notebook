name: Metapool CI

# Controls when the action will run.
on:
  # Triggers the workflow on pull request and push events, only on the master
  # branch
  pull_request:
    branches: [ master ]
  push:
    branches: [ master ]

jobs:
  # name of job
  build:
    # The type of runner that the job will run on (available options are window/macOS/linux)
    runs-on: ubuntu-latest
    # we can add more versions of node.js in the future
    strategy:
      matrix:
        python-version: ['3.6', '3.7', '3.8']

    services:
      postgres:
        # Docker Hub image
        image: postgres:9.5
        env:
          POSTGRES_DB: postgres
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          COVER_PACKAGE: ${{ matrix.cover_package }}

        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # based on https://github.com/actions/example-services/blob/master/.github/workflows/postgres-service.yml#L44-L72
          - 5432/tcp

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # first grab branch from github
      - uses: actions/checkout@v2
        with:
          persist-credentials: false
          fetch-depth: 0

      - name: Set up Node.js enviroment
        uses: actions/setup-node@v1
        with:
          node-version: 14

      - uses: conda-incubator/setup-miniconda@v2
        with:
          activate-environment: tester
          python-version: ${{ matrix.python-version }}
          conda-channels: anaconda, conda-forge, bioconda
          auto-update-conda: true

      - name: Install Qiita
        env:
          COVER_PACKAGE: ${{ matrix.cover_package }}
        shell: bash -l {0}
        run: |
          # we need to download qiita directly so we have "easy" access to
          # all config files
          wget https://github.com/biocore/qiita/archive/dev.zip
          unzip dev.zip

          # pull out the port so we can modify the configuration file easily
          pgport=${{ job.services.postgres.ports[5432] }}
          sed -i "s/PORT = 5432/PORT = $pgport/" qiita-dev/qiita_core/support_files/config_test.cfg

          # PGPASSWORD is read by pg_restore, which is called by the build_db process.
          export PGPASSWORD=postgres

          # Setting up main qiita conda environment
          conda config --add channels conda-forge
          conda create -q --yes -n qiita python=3.9 libgfortran numpy nginx cython redis
          conda activate qiita
          pip install sphinx sphinx-bootstrap-theme nose-timer codecov Click

          conda activate qiita
          pip install qiita-dev/ --no-binary redbiom
          mkdir ~/.qiita_plugins

      - name: Starting Qiita Services
        shell: bash -l {0}
        run: |
          conda activate qiita
          export QIITA_SERVER_CERT=`pwd`/qiita-dev/qiita_core/support_files/server.crt
          export QIITA_CONFIG_FP=`pwd`/qiita-dev/qiita_core/support_files/config_test_local.cfg
          sed "s#/home/runner/work/qiita/qiita#${PWD}/qiita-dev/#g" `pwd`/qiita-dev/qiita_core/support_files/config_test.cfg > ${QIITA_CONFIG_FP}

          export REDBIOM_HOST="http://localhost:7379"

          echo "1. Setting up redis"
          redis-server --daemonize yes --port 7777

          echo "2. Setting up nginx"
          mkdir -p ${CONDA_PREFIX}/var/run/nginx/
          export NGINX_FILE=`pwd`/qiita-dev/qiita_pet/nginx_example.conf
          export NGINX_FILE_NEW=`pwd`/qiita-dev/qiita_pet/nginx_example_local.conf
          sed "s#/home/runner/work/qiita/qiita#${PWD}/qiita-dev/#g" ${NGINX_FILE} > ${NGINX_FILE_NEW}
          nginx -c ${NGINX_FILE_NEW}

          echo "3. Setting up qiita"
          qiita-env make --no-load-ontologies
          qiita plugins update
          qiita-test-install

          echo "4. Starting supervisord => multiple qiita instances"
          supervisord -c ${PWD}/qiita-dev/qiita_pet/supervisor_example.conf
          sleep 10
          cat /tmp/supervisord.log

      - name: Install metapool
        shell: bash -l {0}
        run: |
          conda create -q --yes -n metapool pandas numpy nose pep8 flake8 matplotlib jupyter notebook 'seaborn>=0.7.1' pip openpyxl
          conda activate metapool
          pip install coveralls
          pip install -e ".[all]"

          # create local Qiita connection
          export QIITA_SERVER_CERT=`pwd`/qiita-dev/qiita_core/support_files/server.crt
          echo -e "[qiita-oauth2]\nURL=https://localhost:8383\nCLIENT_ID=19ndkO3oMKsoChjVVWluF7QkxHRfYhTKSFbAVt8IhK7gZgDaO4\nCLIENT_SECRET=J7FfQ7CQdOxuKhQAf1eoGgBAE81Ns8Gu3EKaWFm3IO2JKhAmmCWZuabe0O5Mp28s1\nSERVER_CERT=${QIITA_SERVER_CERT}" > qiita.oauth2.cfg.local

          cat qiita.oauth2.cfg.local
          ls -la $QIITA_SERVER_CERT
          ps -elf | grep qiita

          python -c 'from metapool.metapool import *; read_plate_map_csv(open("notebooks/test_data/Plate_Maps/Finrisk 33-36_plate_map.tsv","r"), qiita_oauth2_conf_fp="qiita.oauth2.cfg.local")'


      - name: Run tests and measure coverage
        shell: bash -l {0}
        run: |
          conda activate metapool
          nosetests --with-coverage --cover-inclusive --cover-package metapool
          coverage report

      - name: Python linter
        shell: bash -l {0}
        run: flake8 metapool setup.py

      - name: Coveralls
        uses: AndreMiras/coveralls-python-action@develop
        with:
          parallel: true
          flag-name: Unit Test

  coveralls_finish:
    needs: build
    runs-on: ubuntu-latest
    steps:
    - name: Coveralls Finished
      uses: AndreMiras/coveralls-python-action@develop
      with:
        parallel-finished: true
