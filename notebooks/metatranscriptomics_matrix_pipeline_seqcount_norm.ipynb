{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import mannwhitneyu, zscore\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from contextlib import suppress\n",
    "from metapool.metapool import *\n",
    "from metapool.plate import PlateReplication\n",
    "from metapool import (make_sample_sheet, requires_dilution, dilute_gDNA,\n",
    "                      find_threshold, autopool, extract_stats_metadata, add_controls, compress_plates)\n",
    "%watermark -i -v -iv -m -h -p metapool,sample_sheet,openpyxl -u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knight Lab shotgun pipeline notebook\n",
    "\n",
    "### What is it?\n",
    "\n",
    "This Jupyter Notebook allows you to automatically produce most of the files you need for completing the Knight Lab shotgun sequencing pipeline.\n",
    "\n",
    "Hopefully, this will not only make it much easier to generate these files, but also keep our information more accurate and tractable.\n",
    "\n",
    "### Here's how it should work.\n",
    "\n",
    "You'll start out with a **sample accession file**, which links each sample to it's approprite matrix tube barcode. Then you'll read in the sample information from a Qiita metadata file. \n",
    "\n",
    "Next, you'll use a Compression Layout form to generate a 384-well dataframe of the sample well-locations and associated extraction plate metadata [`Project Name`, `Project Plate`, `Project Abbreviation`, `Plate elution volume`] The Compression Layout form will import 96-well plate layouts from **VisionMate plate reader output files**, and will assign a 384-well sample well-location based on the 384-well quadrant (`Plate Position`) each 96-well plate is occupying. Then, you'll compare the matrix tube barcodes in your 384-well plate with those stored in folders documenting control matrix tubes to automatically assign controls using the add_controls() function, followed by a validation step. \n",
    "\n",
    "Next, you will merge the sample gDNA concentration **quantification file** from the MiniPico assay, which will enable to you to automatically make a **normalization pick list** for starting the shotgun library prep itself. You can also visualize these concentrations on the plate, allowing you to double check the plate map and gDNA concentration read.\n",
    "\n",
    "You'll then automatically assign barcodes to each sample by specifying a **plate counter**, producing a unique **index pick list** for barcode addition prior to PCR.\n",
    "\n",
    "After finishing the shotgun library prep itself, you'll measure library concentration with the MiniPico assay. The sequencing library concentration **quantification file** will then be merged and used to estimate and visualize pooling parameters, producing a **pooling pick list**. \n",
    "\n",
    "Then, the per-sample information from the whole run can be combined to automatically produce **sample sheets** that you can use to demultiplex the sequencing data produced by Illumina sequencers. You'll need to specify the **sequencing platform** in order to produce an accurate sample sheet. \n",
    "\n",
    "Finally, you'll merge the sequence counts associated with each sample from a **sequence counts file** and produce a **sequence count normalized pooling pick list** for a final high output sequencing run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for Quality Control (QC) of the total nucleic acid extraction\n",
    "\n",
    "This portion of the notebook will read in the output of the MiniPico quantification assays (gDNA / RNA)\n",
    "\n",
    "As inputs, it requires:\n",
    "1. A tab-delimited row-wise plate map that indicates the sample name, well location, and blank status of each sample on the 384 well plate.\n",
    "\n",
    "You can use this google sheet template to generate your plate map:\n",
    "https://docs.google.com/spreadsheets/d/1xPjB6iR3brGeG4bm2un4ISSsTDxFw5yME09bKqz0XNk/edit?usp=sharing\n",
    "\n",
    "The workflow then:\n",
    "1. reads in the plate map and constructs a dataframe\n",
    "2. imports quant files and merged DNA/RNA concentration data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: read in Sample Accession File\n",
    "**Enter the correct path to the sample accession file**. This will serve as a source for relating all subsequent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter all your relevant SAS KL sample accession files from the core here. \n",
    "# Note that they should all be *comma-separated* files, not tab-separated.\n",
    "sample_accession_fps = [\n",
    "    './test_data/Plate_Maps/2024_NPH_007 Sample Processing spreadsheet_SAS KL_w_mmc.csv',\n",
    "    './test_data/Plate_Maps/2024_NPH_008 Sample Processing spreadsheet_SAS KL_w_mmc.csv',\n",
    "    './test_data/Plate_Maps/2024_NPH_009 Sample Processing spreadsheet_SAS KL_w_mmc.csv',\n",
    "    './test_data/Plate_Maps/2024_NPH_010 Sample Processing spreadsheet_SAS KL_w_mmc.csv'\n",
    "]\n",
    " \n",
    "# DO NOT CHANGE ANYTHING below this point\n",
    "def join_dfs(input_fps):\n",
    "    dfs_to_concat = []\n",
    "    for curr_fp in input_fps:\n",
    "        if not os.path.isfile(curr_fp):\n",
    "            raise ValueError(\n",
    "                \"Problem! %s is not a path to a valid file\" % curr_fp)\n",
    "       \n",
    "        curr_df = pd.read_csv(curr_fp, sep=\",\", dtype=str)\n",
    "        dfs_to_concat.append(curr_df)\n",
    "    # next fp\n",
    "    return pd.concat(dfs_to_concat)\n",
    " \n",
    "# TODO: this can be removed once the metadata fp check is fixed\n",
    "sample_accession_fp = sample_accession_fps[0]\n",
    " \n",
    "sample_accession_df = join_dfs(sample_accession_fps)\n",
    " \n",
    "# Note that the below is for NPH *only*, since the core removes leading zeroes from the tube ids\n",
    "sample_accession_df['TubeCode'] = sample_accession_df['TubeCode'].apply(lambda x: f'0{x}')\n",
    " \n",
    "sample_accession_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read in the sample info from Qiita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fp = './test_data/Plate_Maps/15288_20240807-120030.txt'\n",
    "if not os.path.isfile(metadata_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % metadata_fp)\n",
    "\n",
    "metadata = pd.read_csv(metadata_fp, sep='\\t')\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assign the Compression Layout and Fill in Appropriate Info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_layout = [\n",
    "    {\n",
    "        # top left plate\n",
    "        'Plate Position': 1, #as int\n",
    "        'Plate map file': './test_data/Plate_Maps/2024_NPH_Plate_7.tsv',\n",
    "        'Project Name': 'NPH_15288', # PROJECTNAME_QIITAID\n",
    "        'Project Plate': 'Plate_7', # Plate_#\n",
    "        'Project Abbreviation' : 'NPH', # PROJECT ABBREVIATION\n",
    "        'Plate elution volume': 70\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "    {\n",
    "        # top right plate\n",
    "        'Plate Position': 2,\n",
    "        'Plate map file': './test_data/Plate_Maps/2024_NPH_Plate_8.tsv',\n",
    "        'Project Name': 'NPH_15288', # PROJECTNAME_QIITAID\n",
    "        'Project Plate': 'Plate_8', # Plate_#\n",
    "        'Project Abbreviation' : 'NPH', # PROJECT ABBREVIATION\n",
    "        'Plate elution volume': 70\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "    {\n",
    "        # bottom left plate\n",
    "        'Plate Position': 3,\n",
    "        'Plate map file': './test_data/Plate_Maps/2024_NPH_Plate_9.tsv',\n",
    "        'Project Name': 'NPH_15288', # PROJECTNAME_QIITAID\n",
    "        'Project Plate': 'Plate_9', # Plate_#\n",
    "        'Project Abbreviation' : 'NPH', # PROJECT ABBREVIATION\n",
    "        'Plate elution volume': 70\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "    {\n",
    "        # bottom right plate\n",
    "        'Plate Position': 4,\n",
    "        'Plate map file': './test_data/Plate_Maps/2024_NPH_Plate_10.tsv',\n",
    "        'Project Name': 'NPH_15288', # PROJECTNAME_QIITAID\n",
    "        'Project Plate': 'Plate_10', # Plate_#\n",
    "        'Project Abbreviation' : 'NPH', # PROJECT ABBREVIATION\n",
    "        'Plate elution volume': 70\n",
    "        #'Plate_barcode': ''\n",
    "        \n",
    "#         'Plating': 'SF', # initials\n",
    "#         'Extraction Kit Lot': '166032128',\n",
    "#         'Extraction Robot': 'Carmen_HOWE_KF3',\n",
    "#         'TM1000 8 Tool': '109379Z',\n",
    "#         'Primer Date': '2021-08-17', # yyyy-mm-dd\n",
    "#         'MasterMix Lot': '978215',\n",
    "#         'Water Lot': 'RNBJ0628',\n",
    "#         'TM10 8 Tool': '865HS8',\n",
    "#         'Processing Robot': 'Echo550',\n",
    "#         'TM300 8 Tool': 'not applicable',\n",
    "#         'TM50 8 Tool': 'not applicable',\n",
    "#         'instrument_model': 'Illumina MiSeq',\n",
    "#         'run_date': '2023-03-02', # date of MiSeq run\n",
    "#         'Original Name': '' # leave empty\n",
    "    },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_col='Well'\n",
    "plate_df = compress_plates(compression_layout,sample_accession_df,well_col=well_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_dir = './test_data/BLANKS'\n",
    "# ATTENTION: Does your plate include katharoseq controls?\n",
    "# If *yes*, replace None, below, with the path to the directory they are in\n",
    "katharoseq_dir = None\n",
    "\n",
    "plate_df = add_controls(plate_df,blanks_dir,katharoseq_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate plate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_plate_df(plate_df,metadata,sample_accession_df,blanks_dir,katharoseq_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: read in DNA/RNA concentrations and add to plate map\n",
    "\n",
    "**Enter the correct path to the Pico DNA concentration output**. This should be a txt-formatted file produced by the MiniPico assay on the condensed, 384-well plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dna_concs_fp = './test_data/Quant/MiniPico/2024_NPH_Plates_7-10_initial_gDNA_quant.txt'\n",
    "\n",
    "if not os.path.isfile(sample_dna_concs_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the DNA concentration output file**. It should look something like this:\n",
    "    \n",
    "```\n",
    "Results\n",
    "\n",
    "Well ID\tWell\t[Blanked-RFU]\t[Concentration]\n",
    "SPL1\tA1\t5243.000\t3.432\n",
    "SPL2\tC1\t4949.000\t3.239\n",
    "SPL3\tE1\t15302.000\t10.016\n",
    "SPL4\tG1\t4039.000\t2.644\n",
    "SPL5\tI1\t12862.000\t8.419\n",
    "SPL6\tK1\t2840.000\t1.859\n",
    "SPL7\tM1\t3343.000\t2.188\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dna_concs = read_pico_csv(sample_dna_concs_fp, plate_reader='SpectraMax_i3x',conc_col_name='Sample DNA Concentration')\n",
    "\n",
    "plate_df = pd.merge(plate_df, sample_dna_concs, on='Well')\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the correct path to the Pico RNA concentration output**. This should be a txt-formatted file produced by the MiniPico assay on the condensed, 384-well plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rna_concs_fp = './test_data/Quant/MiniPico/2024_NPH_Plates_7-10_initial_RNA_quant.txt'\n",
    "\n",
    "if not os.path.isfile(sample_rna_concs_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rna_concs = read_pico_csv(sample_rna_concs_fp, plate_reader='SpectraMax_i3x',conc_col_name='Sample RNA Concentration')\n",
    "\n",
    "plate_df = pd.merge(plate_df, sample_rna_concs, on='Well')\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize plate DNA/RNA concentrations and plate map:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name for sample well identifier\n",
    "well_col = 'Well'\n",
    "\n",
    "plate_df['Sample'] = plate_df['Sample'].astype(str)\n",
    "\n",
    "# get DNA & RNA concentration information\n",
    "dna_concs = make_2D_array(plate_df, data_col='Sample DNA Concentration', well_col=well_col).astype(float)\n",
    "rna_concs = make_2D_array(plate_df, data_col='Sample RNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "# get information for annotation\n",
    "names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "\n",
    "plot_plate_vals(dna_concs,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.5s')\n",
    "plt.title(\"DNA Concentrations\",fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(rna_concs,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.5s')\n",
    "plt.title(\"RNA Concentrations\",fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Project Plate',y='Sample DNA Concentration',data=plate_df,fliersize=0)\n",
    "sns.stripplot(x='Project Plate',y='Sample DNA Concentration',data=plate_df,color='grey',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for concentration of gDNA (ng/µL) that is too high for complete digestion with TURBO DNAse \n",
    "# when sample gDNA concentration is higher than threshold, a gDNA dilution is needed\n",
    "threshold = 40 #(ng/µL)\n",
    "\n",
    "for plate in plate_df['Project Plate'].unique():\n",
    "    plate_needs_dilution = requires_dilution(plate_df.loc[plate_df['Project Plate']==plate,\n",
    "                          ['Sample DNA Concentration']], threshold=threshold)\n",
    "    if plate_needs_dilution:\n",
    "        #Dilution, 1:dilution factor\n",
    "        #sample : total volume (as a factor)\n",
    "        for dilution_factor in range(2,6):\n",
    "            dilute_ = requires_dilution(plate_df.loc[plate_df['Project Plate']==plate,\n",
    "                              ['Sample DNA Concentration']]/dilution_factor, threshold=threshold)\n",
    "            if dilute_:\n",
    "                continue\n",
    "            else:\n",
    "                print(f'You  need to do a 1:{dilution_factor} dilution for {plate}')\n",
    "                break\n",
    "    else:\n",
    "        print(f'You do not need a dilution for {plate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post DNAse QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnase_dna_concs_fp = './test_data/Quant/MiniPico/2024_NPH_Plates_7-10_Post_DNase_DNA_Quant.txt'\n",
    "\n",
    "if not os.path.isfile(dnase_dna_concs_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the DNA concentration output file**. It should be a .txt file and should look something like this:\n",
    "    \n",
    "```\n",
    "##BLOCKS= 1\n",
    "Group: Unknowns\n",
    "Sample\tWells\tRFU_Values\tConcentration\tMean_Conc\tSD\tCV\tDilution\tAdjConc\t\n",
    "01\tA1\t16352.000\t0.434\t0.434\t0.000\t0.0\t\t\t\n",
    "02\tC1\t26061758.000\t37.588\t37.588\t0.000\t0.0\t\t\t\n",
    "03\tE1\t1483519.000\t2.527\t2.527\t0.000\t0.0\t\t\t\n",
    "04\tG1\t3015184.000\t4.712\t4.712\t0.000\t0.0\t\t\t\n",
    "05\tI1\t16574.000\t0.434\t0.434\t0.000\t0.0\t\t\t\n",
    "06\tK1\t14988.000\t0.432\t0.432\t0.000\t0.0\t\t\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnase_dna_concs = read_pico_csv(dnase_dna_concs_fp, plate_reader='SpectraMax_i3x',\n",
    "                                conc_col_name='Post DNAse DNA Concentration')\n",
    "\n",
    "plate_df = pd.merge(plate_df, dnase_dna_concs, on='Well')\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter the correct path to the Pico RNA concentration output**. This should be a txt-formatted file produced by the MiniPico assay on the condensed, 384-well plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnase_rna_concs_fp = './test_data/Quant/MiniPico/2024_NPH_Plates_7-10_Post_DNase_RNA_Quant.txt'\n",
    "\n",
    "if not os.path.isfile(dnase_rna_concs_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnase_rna_concs = read_pico_csv(dnase_rna_concs_fp, plate_reader='SpectraMax_i3x',conc_col_name='Post DNAse RNA Concentration')\n",
    "\n",
    "plate_df = pd.merge(plate_df, dnase_rna_concs, on='Well')\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize cDNA concetration after Reverse Transcription:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column name for sample well identifier\n",
    "well_col = 'Well'\n",
    "\n",
    "# get DNA & RNA post DNAse information\n",
    "dna_dnase = make_2D_array(plate_df, data_col='Post DNAse DNA Concentration', well_col=well_col).astype(float)\n",
    "rna_dnase = make_2D_array(plate_df, data_col='Post DNAse RNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "# get information for annotation\n",
    "names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "\n",
    "plot_plate_vals(dna_dnase,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.5s')\n",
    "plt.title(\"Post-DNAse DNA Concentrations\",fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize plate RNA concentrations and plate map:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(rna_dnase,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.5s')\n",
    "plt.title(\"Post-DNAse RNA Concentrations\",fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3,figsize=(12,4))\n",
    "sns.scatterplot(x='Sample DNA Concentration',y='Sample RNA Concentration',data=plate_df,ax=ax1)\n",
    "sns.scatterplot(x='Sample DNA Concentration',y='Post DNAse DNA Concentration',data=plate_df,ax=ax2)\n",
    "sns.scatterplot(x='Sample DNA Concentration',y='Post DNAse RNA Concentration',data=plate_df,ax=ax3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cDNA quantification\n",
    "**Enter the correct path to the Pico cDNA concentration output**. This should be a txt-formatted file produced by the MiniPico assay on the condensed, 384-well plate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdna_concs_fp = './test_data/Quant/MiniPico/2024_NPH_Plates_7-10_initial_cDNA_quant.txt'\n",
    "\n",
    "\n",
    "if not os.path.isfile(dnase_dna_concs_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the DNA concentration output file**. It should be a .txt file and should look something like this:\n",
    "    \n",
    "```\n",
    "##BLOCKS= 1\n",
    "Group: Unknowns\n",
    "Sample\tWells\tRFU_Values\tConcentration\tMean_Conc\tSD\tCV\tDilution\tAdjConc\t\n",
    "01\tA1\t16352.000\t0.434\t0.434\t0.000\t0.0\t\t\t\n",
    "02\tC1\t26061758.000\t37.588\t37.588\t0.000\t0.0\t\t\t\n",
    "03\tE1\t1483519.000\t2.527\t2.527\t0.000\t0.0\t\t\t\n",
    "04\tG1\t3015184.000\t4.712\t4.712\t0.000\t0.0\t\t\t\n",
    "05\tI1\t16574.000\t0.434\t0.434\t0.000\t0.0\t\t\t\n",
    "06\tK1\t14988.000\t0.432\t0.432\t0.000\t0.0\t\t\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdna_concs = read_pico_csv(cdna_concs_fp, plate_reader='SpectraMax_i3x',\n",
    "                                conc_col_name='Sample cDNA Concentration')\n",
    "\n",
    "plate_df = pd.merge(plate_df, cdna_concs, on='Well')\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cDNA concentratin information\n",
    "cdna_concs = make_2D_array(plate_df, data_col='Sample cDNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "plot_plate_vals(cdna_concs,\n",
    "            annot_str=names,\n",
    "            color_map='viridis',\n",
    "            annot_fmt='.6s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 4))\n",
    "sns.regplot(x=\"Sample RNA Concentration\", y=\"Sample cDNA Concentration\", data=plate_df, ax = ax1)\n",
    "sns.boxplot(x=\"Blank\", y=\"Sample cDNA Concentration\", data=plate_df, ax = ax2)\n",
    "sns.stripplot(x=\"Blank\", y=\"Sample cDNA Concentration\", data=plate_df, ax = ax2,\n",
    "              size=3,color='black',alpha=0.5)\n",
    "\n",
    "sns.boxplot(x=\"Project Plate\", y=\"Sample cDNA Concentration\", data=plate_df, ax = ax3)\n",
    "sns.stripplot(x=\"Project Plate\", y=\"Sample cDNA Concentration\", data=plate_df, ax = ax3,\n",
    "             size=3,color='black',alpha=0.5)\n",
    "ax3.xaxis.set_tick_params(rotation=90)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sample replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of replicates\n",
    "\n",
    "# replicate_dict = {source1_quadrant:destination1_quadrant}\n",
    "# replicate_dict = {source1_quadrant:[destination1_quadrants,destination1_quadrants]}\n",
    "\n",
    "#replicate_dict = {1:[2,3]}\n",
    "\n",
    "# initialize a new PlateReplication object to manage metadata, conversions, and more for you.\n",
    "# initialize w/preferred well_col.\n",
    "well_col = 'Library Well'\n",
    "# 'Library Well' differs from 'Well' because the later specifies the gDNA source well while the former\n",
    "# specifies the well (destination well) that will contain the sequencing library for the sample.\n",
    "pr = PlateReplication(well_col)\n",
    "\n",
    "# set overwrite=False to detect any overwriting of source or destination quads and raise an Error.\n",
    "# replace replicates = None with replicates = replicate_dict to make replicates\n",
    "plate_df = pr.make_replicates(plate_df, replicates=None, overwrite=True)\n",
    "\n",
    "#replicates overlapping sample_wells for other samples shuld raise warning, but will be allowed\n",
    "if 'True' in plate_df['contains_replicates'].unique():\n",
    "    plate_df['contains_replicates'] = True\n",
    "    # get DNA concentratin information\n",
    "    dna_concs = make_2D_array(plate_df, data_col='Sample DNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "    # get information for annotation\n",
    "    names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "\n",
    "    plot_plate_vals(dna_concs,\n",
    "                annot_str=names,\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.6s')\n",
    "else:\n",
    "    plate_df['contains_replicates'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mask arrays for even and odd rows and columns\n",
    "\n",
    "even_rows = [x for x in range(16) if x % 2 == 0]\n",
    "odd_rows = [x for x in range(16) if x % 2 == 1]\n",
    "even_cols = [x for x in range(24) if x % 2 == 0]\n",
    "odd_cols = [x for x in range(24) if x % 2 == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cDNA concentration heatmap, Plate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(cdna_concs[np.ix_(even_rows,even_cols)],\n",
    "                annot_str= names[np.ix_(even_rows,even_cols)],\n",
    "                color_map='viridis',\n",
    "                annot_fmt='.5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cDNA concentration heatmap, Plate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(cdna_concs[np.ix_(even_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(even_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='.5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cDNA concentration heatmap, Plate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(cdna_concs[np.ix_(odd_rows,even_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,even_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='.5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cDNA concentration heatmap, Plate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(cdna_concs[np.ix_(odd_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='.5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: calculate normalization volumes and add to plate map\n",
    "\n",
    "This step will calculate volumes for the DNA normalization pick list.\n",
    "\n",
    "Check the desired values for:\n",
    " - **`ng`**: the desired quantity of DNA in normed plate, in ng\n",
    " - **`total_vol`**: the total volume of normalized DNA, in nL\n",
    " - **`min_vol`**: the minimum quantity of sample to add, in nL\n",
    " - **`resolution`**: the resolution of the Echo, in nL (usually 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targetting 50ng so that all samples get 3.5µL. \n",
    "# Transfer can be done with Mosquito if no PlateReplication is being performed.\n",
    "ng = 50\n",
    "total_vol = 3500\n",
    "min_vol = 25\n",
    "resolution = 2.5\n",
    "\n",
    "dna_vols = calculate_norm_vol(plate_df['Sample cDNA Concentration'], ng=ng, min_vol=min_vol, max_vol=total_vol, resolution=resolution)\n",
    "water_vols = total_vol - dna_vols\n",
    "\n",
    "plate_df['Normalized cDNA volume'] = dna_vols\n",
    "plate_df['Normalized water volume'] = water_vols\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: make pick list\n",
    "\n",
    "Format the Echo-compatible pick list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_picklist = format_dna_norm_picklist(np.array(plate_df['Normalized cDNA volume']),\n",
    "                                         np.array(plate_df['Normalized water volume']),\n",
    "                                         np.array(plate_df['Well']),\n",
    "                                         dest_wells = np.array(plate_df[well_col]),\n",
    "                                         sample_names = np.array(plate_df['Sample']),\n",
    "                                         sample_plates = np.array(plate_df['Compressed Plate Name']),\n",
    "                                         dna_concs = np.array(plate_df['Sample DNA Concentration']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: write pick list to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .txt\n",
    "norm_picklist_fp = './test_output/Input_Norm/YYYY_MM_DD_NPH_7-10_matrix_inputnorm_metaT.txt'\n",
    "\n",
    "if os.path.isfile(norm_picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(norm_picklist_fp, 'w') as f:\n",
    "    f.write(norm_picklist)\n",
    "    \n",
    "!head {norm_picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for assigning barcodes\n",
    "\n",
    "This portion of the notebook will assign index values and construct an Echo picklist file for adding barcodes. \n",
    "\n",
    "As inputs, it requires:\n",
    "1. A plate_df dataframe (from previous step)\n",
    "2. A tab-delimited index combination file, relating index combinations, i5 and i7 index values, and i5 and i7 index locations\n",
    "\n",
    "The workflow then:\n",
    "1. reads in the index combo list\n",
    "2. assigns indices per sample\n",
    "3. produces an Echo-formatted pick list file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in index combo list\n",
    "\n",
    "This is a file that contains every possible i5 and i7 barcode combo on a separate line,\n",
    "along with plate and well location information. It should look something like this:\n",
    "\n",
    "```\n",
    "index combo,index combo seq,i5 name,i5 sequence,i5 well,i5 plate,i7 name,i7 sequence,i7 well,i7 plate\n",
    "0,ACCGACAAACGTTACC,iTru5_01_A,ACCGACAA,A1,iTru5_plate,iTru7_101_01,ACGTTACC,A1,iTru7_plate\n",
    "1,AGTGGCAACTGTGTTG,iTru5_01_B,AGTGGCAA,B1,iTru5_plate,iTru7_101_02,CTGTGTTG,A2,iTru7_plate\n",
    "2,CACAGACTTGAGGTGT,iTru5_01_C,CACAGACT,C1,iTru5_plate,iTru7_101_03,TGAGGTGT,A3,iTru7_plate\n",
    "3,CGACACTTGATCCATG,iTru5_01_D,CGACACTT,D1,iTru5_plate,iTru7_101_04,GATCCATG,A4,iTru7_plate\n",
    "4,GACTTGTGGCCTATCA,iTru5_01_E,GACTTGTG,E1,iTru5_plate,iTru7_101_05,GCCTATCA,A5,iTru7_plate\n",
    "5,GTGAGACTAACAACCG,iTru5_01_F,GTGAGACT,F1,iTru5_plate,iTru7_101_06,AACAACCG,A6,iTru7_plate\n",
    "6,GTTCCATGACTCGTTG,iTru5_01_G,GTTCCATG,G1,iTru5_plate,iTru7_101_07,ACTCGTTG,A7,iTru7_plate\n",
    "7,TAGCTGAGCCTATGGT,iTru5_01_H,TAGCTGAG,H1,iTru5_plate,iTru7_101_08,CCTATGGT,A8,iTru7_plate\n",
    "8,CTTCGCAATGTACACC,iTru5_02_A,CTTCGCAA,I1,iTru5_plate,iTru7_101_09,TGTACACC,A9,iTru7_plate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_combo_fp = './test_output/iTru/new_iTru_combos_Dec2017.csv'\n",
    "\n",
    "if not os.path.isfile(index_combo_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_combos = pd.read_csv(index_combo_fp)\n",
    "index_combos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assign index combo\n",
    "\n",
    "This will pick a set of index combos from the index combo for the number of samples in the `plate_df` DataFrame.\n",
    "\n",
    "Keep track of the barcode combinations used in the lab, and set `starting_combo` equal to the next unused combination.\n",
    "\n",
    "One of way of doing that might be to keep track of the number of plates run, and set `starting_combo` equal to\n",
    "384 * number of plates run + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_counter = 245\n",
    "\n",
    "starting_combo = ((plate_counter - 1) % 384) * 384\n",
    "\n",
    "indices = assign_index(len(plate_df['Sample']), index_combos, start_idx=starting_combo).reset_index()\n",
    "\n",
    "plate_df = pd.concat([plate_df, indices], axis=1)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make index pick list\n",
    "\n",
    "Format the Echo-compatible pick list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_picklist = format_index_picklist(plate_df['Sample'], plate_df[well_col], indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: write pick list to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .txt\n",
    "index_picklist_fp = './test_output/Indices/YYYY_MM_DD_NPH_7-10_matrix_indices_245_metaT.txt'\n",
    "\n",
    "if os.path.isfile(index_picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(index_picklist_fp, 'w') as f:\n",
    "    f.write(index_picklist)\n",
    "\n",
    "!head {index_picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for calculating pooling\n",
    "\n",
    "This portion of the notebook calculates pooling based on fluorescente quantification values, and produces visual outputs to interpret and check values. \n",
    "\n",
    "As inputs, this workflow requires:\n",
    "1. A plate map DataFrame (from previous step)\n",
    "2. MiniPico output (tab-delimited text format with columns 'Concentration' and 'Well')\n",
    "\n",
    "The workflow:\n",
    "1. reads in MiniPico output and calculates estimated library concentration\n",
    "4. calculates pooling values and generates an Echo pick list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: read in MiniPico library concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter correct path to MiniPico file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_concs_fp = './test_data/Quant/MiniPico/2024_NPH_Plates_7-10_clean_library_quant.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_concs = read_pico_csv(lib_concs_fp, plate_reader='SpectraMax_i3x',\n",
    "                          conc_col_name='MiniPico Library DNA Concentration')\n",
    "lib_concs.rename(columns={'Well':well_col},inplace=True)\n",
    "plate_df = pd.merge(plate_df, lib_concs, on=well_col)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: calculate sample concentration from MiniPico\n",
    "\n",
    "You will want to make sure that 'size' is correct for your average library size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df['MiniPico Library Concentration'] = compute_pico_concentration(plate_df['MiniPico Library DNA Concentration'],\n",
    "                                                                        size=500)\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: visualization of MiniPico values\n",
    "\n",
    "This step will present visuals of the results, including:\n",
    "1. Scatter plot of DNA concentrations by Library concentration\n",
    "2. Plate-wise heatmap and histogram showing library concentrations\n",
    "3. per-96-well plate heatmaps and histograms showing library concentrations and sample names\n",
    "4. Plate-wise heatmap showing pooling values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration by sample DNA concentration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "sns.regplot(x=\"Sample RNA Concentration\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax1);\n",
    "sns.regplot(x=\"Sample cDNA Concentration\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax2);\n",
    "sns.boxplot(x=\"Blank\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax3);\n",
    "sns.swarmplot(x=\"Blank\", y=\"MiniPico Library DNA Concentration\", data=plate_df, ax = ax3,\n",
    "              size=3,color='black',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_gdna_concs = plate_df.loc[plate_df['Blank']==True,'Sample RNA Concentration']\n",
    "samples_gdna_concs = plate_df.loc[plate_df['Blank']==False,'Sample RNA Concentration']\n",
    "mannwhitneyu(samples_gdna_concs, blanks_gdna_concs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_gdna_concs = plate_df.loc[plate_df['Blank']==True,'Sample cDNA Concentration']\n",
    "samples_gdna_concs = plate_df.loc[plate_df['Blank']==False,'Sample cDNA Concentration']\n",
    "mannwhitneyu(samples_gdna_concs, blanks_gdna_concs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks_lib_concs = plate_df.loc[plate_df['Blank']==True,'MiniPico Library Concentration']\n",
    "samples_lib_concs = plate_df.loc[plate_df['Blank']==False,'MiniPico Library Concentration']\n",
    "mannwhitneyu(samples_lib_concs, blanks_lib_concs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, whole plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get concentration and pooling values for plotting\n",
    "concs = make_2D_array(plate_df, data_col=\"MiniPico Library Concentration\", well_col=well_col).astype(float)\n",
    "dna = make_2D_array(plate_df, data_col='Sample DNA Concentration', well_col=well_col).astype(float)\n",
    "\n",
    "# get information for annotation\n",
    "names = make_2D_array(plate_df, data_col='Sample', well_col=well_col)\n",
    "i5 = make_2D_array(plate_df, data_col='i5 name', well_col=well_col)\n",
    "i7 = make_2D_array(plate_df, data_col='i7 name', well_col=well_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs, color_map='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plate maps for individual constituent plates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(even_rows,even_cols)],\n",
    "                    annot_str= names[np.ix_(even_rows,even_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(even_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(even_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(odd_rows,even_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,even_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library concentration heatmap, Plate 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plate_vals(concs[np.ix_(odd_rows,odd_cols)],\n",
    "                    annot_str= names[np.ix_(odd_rows,odd_cols)],\n",
    "                    color_map='viridis',\n",
    "                    annot_fmt='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: calculate pooling values for MiniPico with autopool\n",
    "\n",
    "This step will calculate the sample pooling, and update the sample data frame with the pool info.\n",
    "There are two automated methods to pool:\n",
    "1. **norm**: This will attempt to generate a normalized pool, automatically inferring the best parameter for pooling.\n",
    "    - ***pool_failures***:\n",
    "        - _high_: will pool failures at the highest pooling volume from optimized pooling.\n",
    "        - _low_: will pool failures at the lowest pooling volume from optimized pooling.\n",
    "\n",
    "2. **evp**: This will pool an even volume per sample.\n",
    "    - ***total_vol***: (Optional, Default: 100µL) The total volume to pool, in uL. Each sample will be pooled at 1/N of that volume, where N is total number of samples in the prep.\n",
    "\n",
    "3. **automate**: (Optional, Default = True) When False, this argument will allow one input parameters for **Legacy** arguments. \n",
    "\n",
    "> **Legacy**\n",
    "> There are legacy parameters to control pooling behaviors when autopool automation (automate=True) returns a poor result. To use these parameters, one must pass automate=False.\n",
    "\n",
    ">   - **min_conc**: (default: 0) This is the minimum concentration for a sample to be considered for pooling.\n",
    "    Set to 0 to pool all samples, regardless of concentration. Increasing this will have the \n",
    "    effect of increasing pool concentration, at the expense of samples dropping out. \n",
    ">   - **floor_conc**: This is the lowest concentration equivalent for which a sample will be \n",
    "    accurately pooled. Samples below this concentration will be pooled to the volume that they \n",
    "    would have been if they were actually that concentration. For example, if `floor_conc=20`, \n",
    "    and a sample at 20 nM pools at 500 nL, a sample at 40 nM will pool at 250 nL but a sample at \n",
    "    10 nM will still pool at 500 nL (rather than 1000). Increasing this value will have the effect \n",
    "    of increasing pool concentration, but decreasing read counts for low-concentration samples. \n",
    ">   - **total_nmol**: This is the total number of molecules to shoot for in the pool. Increasing\n",
    "    this will increase the overall volume of the pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot pooling volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = find_threshold(plate_df['MiniPico Library Concentration'], plate_df['Blank'])\n",
    "plate_df = autopool(plate_df,method='evp',total_vol=190)\n",
    "\n",
    "# visualize\n",
    "print(\"Floor concentration: {}\".format(threshold))\n",
    "vols = make_2D_array(plate_df, data_col='MiniPico Pooled Volume', well_col=well_col).astype(float)\n",
    "conc, vol = estimate_pool_conc_vol(plate_df['MiniPico Pooled Volume'], plate_df['MiniPico Library Concentration'])\n",
    "print(\"Pool concentration: {:.2f}\".format(conc))\n",
    "print(\"Pool volume: {:.2f}\".format(vol))\n",
    "with suppress(np.linalg.LinAlgError):\n",
    "    plot_plate_vals(vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = make_2D_array(plate_df, data_col='MiniPico Pooled Volume', well_col=well_col).astype(float)\n",
    "sns.scatterplot(x='MiniPico Library Concentration', y='MiniPico Pooled Volume',data=plate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: write pooling pick list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .csv\n",
    "picklist_fp = './test_output/Pooling/YYYY_MM_DD_NPH_7-10_matrix_evp.csv'\n",
    "\n",
    "if os.path.isfile(picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklist = format_pooling_echo_pick_list(vols, max_vol_per_well=30000)\n",
    "with open(picklist_fp,'w') as f:\n",
    "    f.write(picklist)\n",
    "\n",
    "!head {picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write DataFrame to file\n",
    "\n",
    "We want to keep all that useful information together in one place so it can be easily parsed later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write the sample info DataFrame as .txt\n",
    "plate_df_fp = './test_output/QC/YYYY_MM_DD_NPH_7_10_matrix_df.txt'\n",
    "\n",
    "if os.path.isfile(plate_df_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df.to_csv(plate_df_fp, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Make sample sheet\n",
    "\n",
    "This workflow takes the pooled sample information and writes an Illumina sample sheet that can be given directly to the sequencing center. \n",
    "\n",
    "As inputs, this notebook requires:\n",
    "1. A plate map DataFrame (from previous step)\n",
    "\n",
    "The workflow:\n",
    "1. formats sample names as bcl2fastq-compatible\n",
    "2. formats sample data\n",
    "3. sets values for sample sheet fields and formats sample sheet.\n",
    "4. writes the sample sheet to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Format sample names to be bcl2fastq-compatible\n",
    "\n",
    "bcl2fastq requires *only* alphanumeric, hyphens, and underscore characters. We'll replace all non-those characters\n",
    "with underscores and add the bcl2fastq-compatible names to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df['sample sheet Sample_ID'] = plate_df['Sample'].map(bcl_scrub_name)\n",
    "\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: format sample sheet data\n",
    "\n",
    "This step formats the data columns appropriately for the sample sheet, using the values we've calculated previously.\n",
    "\n",
    "The newly-created bcl2fastq-compatible names will be in the **`Sample ID`** and **`Sample Name`** columns. The\n",
    "original sample names will be in the **`Description`** column.\n",
    "\n",
    "Modify **`lanes`** to indicate which lanes this pool will be sequenced on.\n",
    "\n",
    "**Project Name and Project Plate values will be placed in the **`Sample_Project`** and **`Sample_Name`**\n",
    "columns, respectively.\n",
    "\n",
    "**`sequencer`** is important for making sure the i5 index is in the correct orientation for demultiplexing. `NovaSeq6000`, `HiSeq4000`, `HiSeq3000`, `NextSeq`, `MiniSeq`, and `iSeq` all require reverse-complemented i5 index sequences. If you enter one of these exact strings in for `sequencer`, it will revcomp the i5 sequence for you.\n",
    "\n",
    "`HiSeq2500`, `MiSeq`, `NovaSeqX`, and `NovaSeqXPlus` will not revcomp the i5 sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer = 'iSeq'\n",
    "lanes = [1]\n",
    "plate_df['vol_extracted_elution_ul'] = 70\n",
    "\n",
    "# Knight Lab Nextera is also valid for library_construction_protocol\n",
    "metadata = {\n",
    "    'Bioinformatics': [\n",
    "        {\n",
    "         'Sample_Project': 'NPH_15288',\n",
    "         'QiitaID': '15288',\n",
    "         'BarcodesAreRC': 'True',\n",
    "         'ForwardAdapter': 'GATCGGAAGAGCACACGTCTGAACTCCAGTCAC',\n",
    "         'ReverseAdapter': 'GATCGGAAGAGCGTCGTGTAGGGAAAGGAGTGT',\n",
    "         'HumanFiltering': 'True',\n",
    "         'library_construction_protocol': 'Knight Lab Kapa HyperPlus',\n",
    "         'experiment_design_description': 'stool metatranscriptomics',\n",
    "#          'contains_replicates':plate_df['contains_replicates'].all(),\n",
    "        },\n",
    "    ],\n",
    "    'Contact': [\n",
    "        {\n",
    "         'Sample_Project': 'NPH_15288',\n",
    "         # non-admin contacts who want to know when the sequences\n",
    "         # are available in Qiita\n",
    "         'Email': 'tboyer@health.ucsd.edu'\n",
    "        },\n",
    "    ],\n",
    "    'Assay': 'Metatranscriptomic',\n",
    "    'SheetType': 'standard_metat',\n",
    "    'SheetVersion':'10'\n",
    "}\n",
    "\n",
    "sheet = make_sample_sheet(metadata, plate_df, sequencer, lanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Write the sample sheet to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the samplesheet as .csv\n",
    "sample_sheet_fp = './test_output/SampleSheets/YYYY_MM_DD_NPH_7-10_matrix_samplesheet_245.csv'\n",
    "\n",
    "if os.path.isfile(sample_sheet_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sample_sheet_fp,'w') as f:\n",
    "    sheet.write(f)\n",
    "    \n",
    "!head -n 30 {sample_sheet_fp}\n",
    "!echo ...\n",
    "!tail -n 15 {sample_sheet_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Read Distribution Summary and Pool Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: import and merge per_sample read distributions\n",
    "\n",
    "Import a tsv file with read_counts from per_sample_fastq files and merge with growing plate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reads counts from file to dataframes\n",
    "\n",
    "read_counts_df = pd.read_csv('./test_data/Demux/2024_NPH_7-10_fastqc_sequence_counts_plot_matrix.tsv',\n",
    "                                 sep='\\t')\n",
    "raw_read_counts_df = read_counts_df.loc[~read_counts_df['Category'].str.contains('trimmed')]\n",
    "filtered_read_counts_df = read_counts_df.loc[read_counts_df['Category'].str.contains('trimmed')]\n",
    "\n",
    "##Can also import counts from Qiita per_sample_FASTQ summaries.  \n",
    "# per_sample_fastq_counts_df = pd.read_csv('./test_data/Demux/YYYY_MM_DD_Celeste_Adaptation_16_17_18_21_per_sample_fastq.tsv',\n",
    "#                                          sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge read_counts_df with plate_df \n",
    "\n",
    "plate_df_w_reads = merge_read_counts(plate_df,raw_read_counts_df, reads_column_name='Raw Reads')\n",
    "\n",
    "plate_df_w_reads = merge_read_counts(plate_df_w_reads,filtered_read_counts_df,\n",
    "                                     reads_column_name='Filtered Reads')\n",
    "\n",
    "# plate_df_w_reads = merge_read_counts(plate_df_w_reads,per_sample_fastq_counts_fp,\n",
    "#                                      reads_column_name='Qiita Reads')\n",
    "\n",
    "plate_df_w_reads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_column = 'Raw Reads'\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "# evenness plot\n",
    "rmax = int(round(plate_df_w_reads[reads_column].max(),-2))\n",
    "survival_df = pd.concat([read_survival(plate_df_w_reads.loc[plate_df_w_reads['Blank'] == True,\n",
    "                                                            reads_column], label='Blanks',rmax=rmax),\n",
    "                         read_survival(plate_df_w_reads.loc[plate_df_w_reads['Blank'] == False,\n",
    "                                                            reads_column], label='Samples',rmax=rmax)])\n",
    "\n",
    "ax3.set_xlabel(reads_column)\n",
    "ax3.set_ylabel('Samples')\n",
    "survival_df.plot(color = ['coral','steelblue'],ax=ax1)\n",
    "ax1.set_xlabel(reads_column)\n",
    "ax1.set_ylabel('Samples')\n",
    "\n",
    "##Histogram\n",
    "sns.histplot(plate_df_w_reads[reads_column],ax=ax3)\n",
    "\n",
    "##Regressopm\n",
    "sns.regplot(x=\"MiniPico Library DNA Concentration\", y=reads_column, data=plate_df_w_reads, ax = ax2);\n",
    "\n",
    "#Boxplot\n",
    "sns.boxplot(x=\"Blank\", y=reads_column, data=plate_df_w_reads, ax = ax4);\n",
    "sns.stripplot(x=\"Blank\", y=reads_column, data=plate_df_w_reads, ax = ax4,\n",
    "              size=3,color='black',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate iSeqnorm pooling volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df_normalized = calculate_iseqnorm_pooling_volumes(plate_df_w_reads,dynamic_range=5, normalization_column='Raw Reads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "vols = make_2D_array(plate_df_normalized, data_col='iSeq normpool volume', well_col=well_col).astype(float)\n",
    "conc, vol = estimate_pool_conc_vol(plate_df_normalized['iSeq normpool volume'], plate_df_normalized['MiniPico Library Concentration'])\n",
    "print(\"Pool concentration: {:.2f}\".format(conc))\n",
    "print(\"Pool volume: {:.2f}\".format(vol))\n",
    "with suppress(np.linalg.LinAlgError):\n",
    "    plot_plate_vals(vols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate read depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots estimate of read depth proportion, and returns a df with estimates. \n",
    "plate_df_normalized_with_estimates = estimate_read_depth(plate_df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: write pooling picklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the picklist as .csv\n",
    "picklist_fp = './test_output/Pooling/YYYY_MM_DD_NPH_7_10_matrix_iSeqnormpool.csv'\n",
    "\n",
    "if os.path.isfile(picklist_fp):\n",
    "    print(\"Warning! This file exists already.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklist = format_pooling_echo_pick_list(plate_df_normalized,\n",
    "                                         pooling_vol_column='iSeq normpool volume',\n",
    "                                         max_vol_per_well=30000)\n",
    "with open(picklist_fp,'w') as f:\n",
    "    f.write(picklist)\n",
    "\n",
    "!head {picklist_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "473px",
    "width": "381px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "740px",
    "left": "0px",
    "right": "1407.6666259765625px",
    "top": "112px",
    "width": "211.705px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
